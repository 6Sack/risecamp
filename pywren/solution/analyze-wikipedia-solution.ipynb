{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyWren RISECamp, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analytics with PyWren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use PyWren explore the Wikipedia data.\n",
    "\n",
    "\n",
    "## 1. The data\n",
    "We have a number wikipedia files stored in our RISECamp S3 bucket.\n",
    "Let's just take a peek at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some libraries that are useful for this tutorial\n",
    "import sys\n",
    "from training import *\n",
    "\n",
    "# We need to load PyWren and create an executor instance\n",
    "import pywren\n",
    "pwex = pywren.default_executor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll first get the list of files\n",
    "filenames = list_keys_with_prefix(wikipedia_bucket, \"wikistats_20090505_restricted-01/\")\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take5(filename):\n",
    "    data = read_from_s3(wikipedia_bucket, filename)\n",
    "    result = data.split(\"\\n\")[:5]\n",
    "    return result\n",
    "\n",
    "future = pwex.call_async(take, filenames[0])\n",
    "print(future.result())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately this is not very readable because result() returns a list. We can make it prettier by printing each record on its own line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in future.result():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Count\n",
    "Let’s see how many records in total are in this data set (this command will take a while, so read ahead while it is running)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(filename):\n",
    "    data = read_from_s3(wikipedia_bucket, filename)\n",
    "    return (len(data.split(\"\\n\")) if data else 0)    \n",
    "\n",
    "futures = pwex.map(count, filenames)\n",
    "pywren.wait(futures)\n",
    "\n",
    "result = sum([f.result() for f in futures])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should launch 73 PyWren tasks. After finishing the job, let's plot again to check the execution. Now it should be more interesting than the simple job above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_pywren_execution(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visits for English Pages\n",
    "Recall from above when we peek the date, that the second field is the “project code” and contains information about the language of the pages. For example, the project code “en” indicates an English page. Let’s calculate the page counts of english pages, grouped by dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from functools import reduce\n",
    "\n",
    "def aggregate_count(key_value_list):\n",
    "    def reduce_f(obj1, obj2):\n",
    "        return(obj1[0], obj1[1] + obj2[1])\n",
    "    counts = [reduce(reduce_f, group) for _, group \n",
    "          in groupby(sorted(key_value_list), key=itemgetter(0))]\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def english_page_count(filename):\n",
    "    data = read_from_s3(wikipedia_bucket, filename)\n",
    "    # filter out the english pages\n",
    "    en_pages = [d for d in data.split(\"\\n\") \n",
    "                if len(d.split(\" \")) >= 4 and d.split(\" \")[1] == \"en\"]\n",
    "    # projection to create (date, pagecount) pairs\n",
    "    en_kvpair_list = [(p.split(\" \")[0][:8], int(p.split(\" \")[3])) for p in en_pages]\n",
    "\n",
    "    return aggregate_count(en_kvpair_list)\n",
    "    \n",
    "futures = pwex.map(english_page_count, filenames)\n",
    "pywren.wait(futures)\n",
    "\n",
    "results = [f.result() for f in futures]\n",
    "en_page_counts_by_date = aggregate_count([x for y in results for x in y])\n",
    "print(en_page_counts_by_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
