{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground RISE Camp Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For background, please see the slides from this morning's talk on Ground. You can find them [here](). (***TODO: Add link to slides.***) This Jupyter notebook is running in a Docker container that already has a Ground instance as well as a Postgres server up and running. There isn't any more set up for us to do, so let's jump right in!\n",
    "\n",
    "In this tutorial, we will first introduce the basic concepts of Ground by walking through an instrumented analytics scenario. You will use Ground to track git commits and some simple data. We will run the code in the git repo on the data and automatically publish some lineage information into Ground. We will use the information automatically sent to Ground to inspect the lineage and make sure everything happened as we expected.\n",
    "\n",
    "Next, we will look at managing machine learning models with Ground as a specific case study and explore how one might use Ground to debug unexpected problems efficiently and simply.\n",
    "\n",
    "Lastly, we will look at how to use the Ground Python client to build a simple Aboveground application that takes in a a directory and automatically publishes data context about the files in that directory to Ground."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Basic Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To get started with Ground, we will use some of the \"Aboveground\" services that we have already developed. Aboveground services are tools that users use to interface with Ground at a higher semantic level than the simple node-and-edge-based API.\n",
    "\n",
    "We will begin by using a tool that autopopulates Github repositories into Ground. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ground_git_client\n",
    "\n",
    "REPO_NAME = \"ground-context/risecamp\"\n",
    "ground_git_client.add_repo(REPO_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some code that Ground is aware of, we are going to want to do something with code. The particular repository that we populated has some simple Python scripts that are \"Ground-aware\"\\* as well a small amount of data for us to analyze in the form of a CSV file. \n",
    "\n",
    "We're going to download that repository locally using the `download_repo` command below. You can find the repo online [here](). We will run a simple script that's going to take our CSV data and split up our currently single-column data into three columns of type `int`, `string`, and `int`.\n",
    "\n",
    "However, before doing that, we need to make sure that Ground knows about the base dataset that we are transforming. Using another Aboveground tool that we have already developed, you can automatically let Ground know about this new dataset. This tool will populate Ground with some useful information about the file including the file type, the size of the file, and the path to the file.\n",
    "\n",
    "\\*When we say that these scripts are Ground-aware, we mean that we have instrumented them to know how to interact with Ground and automatically publish useful data context into Ground in the due course of their execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ground_file_client\n",
    "\n",
    "FILE_PATH = \"repo/data.txt\"\n",
    "ground_file_client.add_file(FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that Ground knows about our base dataset, we can go about transforming it. Since the scripts that we are using are Ground-aware, they are going to generate lineage information in Ground as a part of transforming the data. It will tell Ground that it's created a new dataset based on the old input dataset, and it will associate this lineage information with the latest version of the source code that was used for the transformation.\n",
    "\n",
    "This step will take a minute to run because it is going to scan through a lot of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# execute the Python script in the repository in the repository cloned above\n",
    "!cd repo && python column_splitter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've spent a bunch of time populating information into Ground, it's time to see everything we've done. Using the Ground API client, for which you can find complete documentation [here]()(***TODO: add link to documentation and help command to the GroundClient***), determine the following pieces of information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ground import GroundClient\n",
    "gc = GroundClient()\n",
    "\n",
    "# the id of the node version for the base dataset (hint: you can use the latest API) -- get_node_latest(node_key)\n",
    "\n",
    "# the lineage edge and version conencting the two datasets\n",
    "# for now the key is \"data.txt_to_split_data.csv\" -- get_lineage_edge_latest(le_key) (to be changed for final version)\n",
    "\n",
    "# all of the tags of the derived dataset -- get_node_version(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground & ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One use case we have been exploring as a part of the Ground agenda recently is managing the lifecycles of machine learning models using Ground. In particular, we are interested in tracking the code and the data combined to output a particular model. As we've already learned, Ground treats versioning as a first-class citizen. As a result, it is easy to imagine a scenario in which Ground would help users track which particular version of data was used to train a model for reproducibility purposes. \n",
    "\n",
    "As an aside, it is an interesting and open research question how we track and version datasets. We're first going to initialize the tutorial. Run the cell below this before moving on because it takes a minute to set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ml import tutorial\n",
    "tutorial.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular example, we will be toying with a model that predicts a tweet's location based on the content of the tweet. Below is a rough description of the pipeline that we have put together:\n",
    "\n",
    "1. Tweets are crawled from Twitter to generate a training set and a test set.\n",
    "2. Those tweets are cleaned and normalized.\n",
    "3. The model is trained on the cleaned training set. \n",
    "4. The model trained in step 3 is validated on the cleaned testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model training pipeline](ml/target_test_simple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a part of these exercises, we have pre-built a number of helper functions that you might find useful as you go through the steps below. Make sure you read these function defintions before continuing!\n",
    "\n",
    "* `setup`: prepares and configures the system and data for this tutorial\n",
    "* `show_me_data`: displays a dataframe containing the data we will use throughout this tutorial\n",
    "* `get_ground_metadata`: queries ground and displays all relevant metadata for this tutorial\n",
    "* `test_model`: executes the machine learning pipeline to train and test a model, reports prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tutorial.show_me_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = tutorial.test_model()\n",
    "print(output.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we have a baseline model, and it does pretty well! The default case would be to guess the United States, asbout 35% of tweets come from the US. We're clearly doing a good bit better than that. However, we're not satisfied with this quite yet; we'd like to improve this, and we have a guess that improving the cleaning process will help improve our model accuracy. We've set up the skeleton of a `clean` function below for you to fill in. You're welcome to try anything you'd like to improve the cleaning process!\n",
    "\n",
    "For those who might be less familiar with data cleaning and ETL, here's a simple suggestion and code snippet that you can try out in the cell below. You're welcome to modify it as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile ml/my_cleaner.py\n",
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import HTMLParser\n",
    "import preprocessor as tweet_preprocessor\n",
    "html_parser = HTMLParser.HTMLParser()\n",
    "\n",
    "def clean(df):\n",
    "    df[\"tweet\"].apply(html_parser.unescape)\n",
    "    df[\"tweet\"].apply(tweet_preprocessor.tokenize)\n",
    "    # and so on...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined this function, let's test the model again. It's okay if you have to run through these steps a few times while testing your cleaning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = tutorial.test_model()\n",
    "print(output.decode('UTF-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly enough, no matter what we put into the `clean` method above, we see that the accuracy of the model that we're training has plummetted, likely at no fault of our own given we haven't changed much here.\n",
    "\n",
    "The question we have to answer next is what changed that caused our pipeline to break. We can come up with a long list of things that might have broken. If you're stuck, we've written a description below that will help walk you through the investigative steps. \n",
    "\n",
    "**HINTS**: \n",
    "\n",
    "1. You're probably going to find the tutorial APIs above very helpful. \n",
    "2. The ultimate solution will be to modify the `clean` function somehow. We provided a skeleton below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your experiments and exploration go here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile ml/my_cleaner.py\n",
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean(df):\n",
    "    pass\n",
    "    # your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANOTHER HINT**: We suggest you start off by looking at the metadata stored in Ground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model should now be back to normal.\n",
    "output = tutorial.test_model()\n",
    "print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full solution is provided [here]()(***TODO***: Add link to notebook with full solution.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending Ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will walk you through how you might go about extending Ground to populate your own data context. Before we go any further, let's first reset our Ground instance. If you mistakenly add data to Ground as you do this exercise, you can run the following cell to wipe Ground and start over anew:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ground_setup import reset_ground\n",
    "\n",
    "reset_ground()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start writing our own Aboveground tool, let's first dig into the the Ground file populator component works a little more. Let's begin by opening the `ground_file_client.py` file in another tab. After walking through the comments there, return here to continue with the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on the examples of the Ground file client, we're going to now implement a Ground directory client. Instead of an `add_file` method in that example, we're going to implement an `add_dir` method that takes in the path of a directory, generates a of list all the files in it, and adds each one of those files to Ground. \n",
    "\n",
    "The data model we are imagining will create a node for the directory and one for each of the files in the directory. Each one of the files will be associated with the directory via an edge.\n",
    "\n",
    "The simplest version of this can simply leverage the existing file client, in order to add the files and then link the files to the directory node. We encourage you to explore the API and add other features that you can think of. For example, one optional feature would be to generate lineage edges, which would indicate that it was the `ground_dir_client` script that actually created the nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ground import GroundClient\n",
    "\n",
    "gc = GroundClient()\n",
    "\n",
    "def add_dir(dir_name):\n",
    "    # your solution here\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
