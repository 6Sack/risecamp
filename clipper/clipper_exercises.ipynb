{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: API Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "from clipper_admin import ClipperConnection, DockerContainerManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Clipper on Docker. Link to API Docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_conn = ClipperConnection(DockerContainerManager(\"localhost\"))\n",
    "clipper_conn.start_clipper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Docker and see that there are now 3 Docker containers running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\r\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At its most basic, Clipper is a function server. To start with, lets deploy a very simple function to Clipper. We'll start with the classic Big Data hello-world example: word count.\n",
    "\n",
    "First, we'll define our word count function. Clipper may provide multiple inputs to a function at once, because many machine learning models can take advantage of data parallelism when performing inference to improve performance. Because of this, we define a second function that takes a list of documents as an argument and returns the word count of each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    words = text.split()\n",
    "    return len(words)\n",
    "\n",
    "# The function you deploy to Clipper must take a list of inputs, so we\n",
    "# wrap our core logic in loop.\n",
    "def count_words_in_docs(docs):\n",
    "    counts = []\n",
    "    for d in docs:\n",
    "        count = str(count_words(d))\n",
    "        counts.append(count)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_one = \"Hello world. Foo bar baz.\"\n",
    "example_two = \"I'm learning so much at the inaugural RISE Camp.\"\n",
    "\n",
    "print(\"There are %d words in the first example.\" % count_words(example_one))\n",
    "count_words_in_docs([example_one, example_two])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now deploy this function directly to Clipper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from clipper_admin.deployers import python as python_deployer\n",
    "python_deployer.create_endpoint(clipper_conn, name=\"wordcount\", input_type=\"string\", func=count_words_in_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try querying the newly created application with curl. You can run this directly in the Jupyter notebook or locally on your laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!curl -X POST --header \"Content-Type:application/json\" -d '{\"input\": \"The sky above the port was the color of television, tuned to a dead channel.\"}' 127.0.0.1:1337/wordcount/predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect Clipper's internal metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_conn.inspect_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_conn.get_all_apps(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_conn.get_all_models(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's update our word count function to count word frequencies instead of just the total number of words in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "def word_freq(text):\n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    text = text.translate(None, string.punctuation)\n",
    "    words = text.split()\n",
    "    counts = {}\n",
    "    for w in words:\n",
    "        if w in counts:\n",
    "            counts[w] += 1\n",
    "        else:\n",
    "            counts[w] = 1\n",
    "    return json.dumps(counts)\n",
    "    \n",
    "# The function you deploy to Clipper must take a list of inputs, so we\n",
    "# wrap our core logic in loop.\n",
    "def count_word_freqs(docs):\n",
    "    counts = []\n",
    "    for d in docs:\n",
    "        count = word_freq(d)\n",
    "        counts.append(count)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_freq_example = \"Hello world. This is an example sentence. This is another sentence. World world world.\"\n",
    "count_word_freqs([word_freq_example])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now deploy our new and improved word counter to Clipper as a new version of the \"wordcount\" model. If we look above at the output of `clipper_conn.get_all_models` we can see that the currently deployed version is version \"1\". Let's deploy this new function as version \"2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python_deployer.deploy_python_closure(clipper_conn, name=\"wordcount\", version=\"2\", input_type=\"strings\", func=count_word_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!curl -X POST --header \"Content-Type:application/json\" -d '{\"input\": \"The sky above the port was the color of television, tuned to a dead channel.\"}' 127.0.0.1:1337/wordcount/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you decide that you actually liked the previous version better (or more realistically discover a bug), you can roll back to an earlier version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_conn.set_model_version(name=\"wordcount\", version=\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!curl -X POST --header \"Content-Type:application/json\" -d '{\"input\": \"The sky above the port was the color of television, tuned to a dead channel.\"}' 127.0.0.1:1337/wordcount/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Example Application - Birds vs Airplanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part 2 of this exercise, you will build a real machine application that uses computer vision models to classify images.\n",
    "\n",
    "You will create an application that labels images as pictures of either birds or planes. You will use the CIFAR-10 dataset as the source of these images.\n",
    "\n",
    "These images have already been downloaded and are available locally at `~/cifar`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cifar\n",
    "\n",
    "The first step in building any application, using machine-learning or otherwise, is to understand the application requirements. Load the dataset into the notebook so you can examine it and better understand the dataset you will be working with. The `cifar_utils` library provides several utilities for working with CIFAR data – we will make use of one of them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cifar_utils\n",
    "\n",
    "cifar_loc = os.path.expanduser(\"cifar/\")\n",
    "test_x, test_y = cifar_utils.filter_data(\n",
    "    *cifar_utils.load_cifar(cifar_loc, cifar_filename=\"cifar_test.data\", norm=True))\n",
    "train_x, train_y = cifar_utils.filter_data(\n",
    "    *cifar_utils.load_cifar(cifar_loc, cifar_filename=\"cifar_train.data\", norm=True))\n",
    "raw_x, raw_y = cifar_utils.filter_data(\n",
    "    *cifar_utils.load_cifar(cifar_loc, cifar_filename=\"cifar_test.data\", norm=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the data you've loaded. The size and blurriness of these photos should give you a better understanding of the difficulty of the task you will ask of your machine learning models! If you'd like to see more images, increase the number of rows of images displayed -- the last argument to the function -- to a number greater than 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "cifar_utils.show_example_images(raw_x, raw_y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an application\n",
    "\n",
    "In order to query Clipper for predictions, you need to create an application. Each application specifies a name, the query input datatype, the selection policy, and a latency service level objective. Once you register an application with Clipper, the system will create a REST endpoint for handling prediction requests.\n",
    "\n",
    "By associating the query interface with a specific application, Clipper allows frontend developers the flexibility to have multiple applications running in the same Clipper instance. Applications can request predictions from any model in Clipper. This allows a single Clipper instance to serve multiple machine-learning applications. It also provides a convenient mechanism for beta-testing or incremental rollout by creating experimental and stable applications for the same set of queries.\n",
    "\n",
    "For this tutorial, you will create an application named \"cifar_demo\". Note that Clipper allows you to create the application before deploying the models. Clipper will be moving to a label-based model specification mechanism soon, so that in the future you won't have to explicitly enumerate all the models you want to query up front.\n",
    "\n",
    "Registering the `cifar-demo` application with Clipper will have the following effect on your setup: <img src=\"img/register_app.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "> *Don't worry if this command seems to take a long time. Before starting Clipper, the Docker containers must be downloaded from Docker Hub. These containers are fairly large and may take awhile to download depending on the speed of your internet connection.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "app_name = \"cifar-demo\"\n",
    "# If the model (which we will later link to our application) doesn't\n",
    "# return a prediction in time, predict label 0 (bird) by default\n",
    "default_output = \"0\"\n",
    "\n",
    "clipper_conn.register_application(\n",
    "    app_name,\n",
    "    \"doubles\",\n",
    "    default_output,\n",
    "    slo_micros=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when you list the applications registered with Clipper, you should see the newly registered \"cifar-demo\" application show up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_conn.get_all_apps(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start serving\n",
    "\n",
    "Now that you have registered an application, you can start querying the application for predictions. In this case,\n",
    "Clipper has created a REST endpoint for your application at:\n",
    "```\n",
    "http://localhost:1337/cifar_demo/predict\n",
    "```\n",
    "\n",
    "You will now start querying Clipper with a simple Python frontend app that computes the average accuracy of the responses after every 100 requests and updates a plot of the results with every iteration.\n",
    "\n",
    "This diagram shows how the accuracy plot is receiving its test predictions: <img src=\"img/serve_predictions.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "Go to the [query_cifar](query_cifar.ipynb) notebook to start the app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic Regression Model\n",
    "\n",
    "When tackling a new problem with machine learning, it's always good to start with simple models and only add complexity when needed. Start by training a logistic regression binary classifier using [Scikit-Learn](http://scikit-learn.org/). This model gets about 68% accuracy on the offline evaluation dataset if you use 10,000 training examples. It gets about 74% if you use all 50,000 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm \n",
    "def train_sklearn_model(m, train_x, train_y):\n",
    "    m.fit(train_x, train_y)\n",
    "    return m\n",
    "lr_model = train_sklearn_model(lm.LogisticRegression(), train_x, train_y)\n",
    "print(\"Logistic Regression test score: %f\" % lr_model.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Logistic Regression Model\n",
    "\n",
    "While 68-74% accuracy on a CIFAR binary classification task is significantly below state of the art, it's already much better than the 50% accuracy your application yields right now by guessing randomly.\n",
    "\n",
    "You can deploy your logistic regression model directly to Clipper without having to worry about how to serialize the model or integrate it with application code.\n",
    "\n",
    "To deploy a model to Clipper, you must assign it a name (\"sklearn_cifar\"), a version (1), and then provide some metadata about the model itself. In this case, you are specifying that you want to run the model using the `sklearn_cifar_container` Docker image in the [Clipper repo](https://hub.docker.com/u/clipper/dashboard/) on Docker Hub. You can assign the model descriptive labels, and specify the input type that this model expects. Finally, you can specify how many *replicas* of the model (how many Docker containers) to launch. Adding more replicas increases the throughput of this model.\n",
    "\n",
    "After completing this step, Clipper will be managing a new container in Docker with your model in it:\n",
    "<img src=\"img/deploy_sklearn_model.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "> *Once again, because you are deploying a Docker image this command may take awhile to download the image. Thanks for being patient!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify_ufos(images):\n",
    "    preds = lr_model.predict(images)\n",
    "    return [str(p) for p in preds]\n",
    "\n",
    "print(\"Predicted labels: {}\".format(classify_ufos(test_x[0:3])))\n",
    "print(\"Correct labels: {}\".format(test_y[0:3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"classify-ufos\"\n",
    "python_deployer.deploy_python_closure(clipper_conn, name=model_name, version=\"1\", input_type=\"doubles\", func=classify_ufos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link your app to your model\n",
    "To use your newly deployed model to generate predictions, it needs to be linked to your Clipper application. Let Clipper know that your `\"cifar-demo\"` app should use the `\"classify-ufos\"` model to serve predictions.\n",
    "\n",
    "In the future, when you deploy new versions of the `\"classify-ufos\"` model, queries to your Clipper application will route to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_conn.link_model_to_app(app_name, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've deployed and linked your model to your app, go ahead and check back on your running frontend application in [query_cifar](query_cifar.ipynb). You should see the accuracy rise from around 50% to the accuracy of your SKLearn model (68-74%), without having to stop or modify your application at all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TensorFlow Model\n",
    "\n",
    "To improve the accuracy of your application further, you will now deploy a TensorFlow convolutional neural network. This model takes a few hours to train, so you will download the trained model parameters rather than training it from scratch. This model gets about 88% accuracy on the test dataset.\n",
    "\n",
    "We have provided a pre-trained TensorFlow model stored at `tf_cifar_model/cifar10_model_full`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf_cifar_model_path = os.path.abspath(\"tf_cifar_model/cifar10_model_full\")\n",
    "tf_session = tf.Session('', tf.Graph())\n",
    "with tf_session.graph.as_default():\n",
    "    saver = tf.train.import_meta_graph(\"%s.meta\" % tf_cifar_model_path)\n",
    "    saver.restore(tf_session, tf_cifar_model_path)\n",
    "\n",
    "def tensorflow_score(session, test_x, test_y):\n",
    "    \"\"\"\n",
    "    NOTE: This predict method expects pre-whitened (normalized) images\n",
    "    \"\"\"\n",
    "    logits = session.run('softmax_logits:0',\n",
    "                           feed_dict={'x:0': test_x})\n",
    "    relevant_activations = logits[:, [cifar_utils.negative_class, cifar_utils.positive_class]]\n",
    "    preds = np.argmax(relevant_activations, axis=1)\n",
    "    return float(np.sum(preds == test_y)) / float(len(test_y))\n",
    "print(\"TensorFlow ConvNet test score: %f\" % tensorflow_score(tf_session, test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy TensorFlow Model\n",
    "\n",
    "You can now deploy your TensorFlow neural network. Because TensorFlow models cannot be pickled, we cannot deploy them directly using a Python closure. Instead, we will serialize the model using the TensorFlow serialization API and deploy the serialized model directly to Clipper using a custom TensorFlow container.\n",
    "\n",
    "After completing this step, Clipper will send queries to the newly-deployed TensorFlow model instead of the logistic regression Scikit-Learn model, improving the application's accuracy.\n",
    "<img src=\"img/tf_replaces_sklearn_model.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "> *Once again, please patient while the Docker image is downloaded.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_conn.build_and_deploy_model(\n",
    "    name=model_name,\n",
    "    version=\"2\",\n",
    "    input_type=\"doubles\",\n",
    "    model_data_path=os.path.abspath(\"tf_cifar_model\"),\n",
    "    base_image=\"clipper/tf_cifar_container:risecamp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the frontend again and see how the accuracy has gone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, when you are all done, you can stop Clipper and cleanup the docker containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clipper_conn.stop_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 for Clipper",
   "language": "python",
   "name": "clipper_py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
